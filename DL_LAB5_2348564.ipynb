{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs9nSF/JG+cLiol3bWTTG/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SundharessB/Deep-Learning/blob/main/DL_LAB5_2348564.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLPWwtuBIU4P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining constants\n",
        "\n",
        "data_dir = \"C:\\\\Users\\\\USER\\\\OneDrive\\\\Desktop\\\\Datasets\\\\DL\\\\imageClassification - Lab5\\\\Animals-10\"\n",
        "img_size = (224, 224)  # Size of the images\n",
        "batch_size = 32  # Batch size for data generators"
      ],
      "metadata": {
        "id": "R88pdBYRQHu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing ImageDataGenerator for data augmentation and normalization\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalizing pixel values to [0, 1]\n",
        "    validation_split=0.1,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,  # Applying shear transformation with 20% intensity\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True  # Randomly flipping images horizontally\n",
        ")"
      ],
      "metadata": {
        "id": "-UzxCi_YQJ9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',  # Using training subset\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "U10iDrzXQLlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',  # Using validation subset\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "LRqe8OZNQOG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_generator.class_indices)\n",
        "print(\"Class indices:\", train_generator.class_indices)"
      ],
      "metadata": {
        "id": "gLftooWQQRQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating number of steps per epoch for training and validation\n",
        "steps_per_epoch_train = train_generator.samples // batch_size\n",
        "steps_per_epoch_validation = validation_generator.samples // batch_size\n",
        "\n",
        "print(steps_per_epoch_train)\n",
        "print(steps_per_epoch_validation)# Calculating number of steps per epoch for training and validation\n",
        "steps_per_epoch_train = train_generator.samples // batch_size\n",
        "steps_per_epoch_validation = validation_generator.samples // batch_size\n",
        "\n",
        "print(steps_per_epoch_train)\n",
        "print(steps_per_epoch_validation)"
      ],
      "metadata": {
        "id": "n6EDcr_zQU_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layers with batch normalization and ReLU activation\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))"
      ],
      "metadata": {
        "id": "S9AjWyzRQXrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flattening layer to transition from convolutional layers to fully connected layers\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "iaxs3FGnQZhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output layer with softmax activation for multi-class classification\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Using adam optimizer\n"
      ],
      "metadata": {
        "id": "daJFOp5NQbOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "nc7O1JhzQc80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Inference**\n",
        "\n",
        "\n",
        "#### Validation accuracy is approximately 57.92%.\n",
        "#### Validation loss is approximately 1.3318.\n",
        "\n",
        "#### A high validation accuracy and low validation loss indicate that the model is generalizing well to the validation dataset. It took 82 batches for validation.\n"
      ],
      "metadata": {
        "id": "rTwusQDAQu4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator)\n",
        ")"
      ],
      "metadata": {
        "id": "L9xhQNIYQeF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the trained model\n",
        "loss, accuracy = model.evaluate(validation_generator, steps=len(validation_generator))\n",
        "print(\"Validation Loss:\", loss)\n",
        "print(\"Validation Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "HdalI1sjQlKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "#### Thus the task to build a convolutional neural network model to classify the animal images based on species has been implemented successfully.\n",
        "\n",
        "#### While training the model it took 736 steps per epochs, and it gave a good result. The accuracy is increased while the loss is decreased.\n",
        "#### For validation it took 82 steps per epochs. Obtained high validation acccuracy and low validation loss shows that the model is working fine. We can use this model in realtime to classify the images.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVgXpSyxQpw0"
      }
    }
  ]
}